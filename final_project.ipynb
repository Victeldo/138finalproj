{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T03:13:10.363071Z",
     "start_time": "2023-12-20T03:13:08.165886Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'gym[atari]'\"\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow gym keras-rl gym[atari]\n",
    "!pip install tensorflow gym keras-rl 'gym[atari]' 'gym[accept-rom-license]' opencv-python\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T03:13:14.227434Z",
     "start_time": "2023-12-20T03:13:10.364646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym \n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-proccessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T03:13:14.230560Z",
     "start_time": "2023-12-20T03:13:14.228149Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_frame(frame):\n",
    "    frame = np.average(frame,axis = 2)\n",
    "    frame = frame[30:-5,:]\n",
    "    frame = cv2.resize(frame,(84,84),interpolation = cv2.INTER_NEAREST)\n",
    "    frame = np.array(frame,dtype = np.uint8)\n",
    "    frame = np.expand_dims(frame, axis=-1)\n",
    "    frame = np.repeat(frame, 3, axis=-1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class For Memory Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T03:13:14.233909Z",
     "start_time": "2023-12-20T03:13:14.231925Z"
    }
   },
   "outputs": [],
   "source": [
    "#class for storing experiences of the agent. Has a fixed size that when it\n",
    "#reaches the end of, it overwrites what was at the start\n",
    "class Memory(object):\n",
    "    def __init__(self, input_shape, num_actions, buffer_size, batch_size):\n",
    "        self.states = np.zeros((buffer_size,) + input_shape)\n",
    "        self.next_states = np.zeros((buffer_size,) + input_shape)\n",
    "        self.actions = np.zeros(buffer_size, dtype=np.uint8)\n",
    "        self.rewards = np.zeros(buffer_size)\n",
    "        self.terminal = np.zeros(buffer_size)\n",
    "        self.buffer_index = 0\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def save_action(self, state, action, reward, next_state, done):\n",
    "        self.states[self.buffer_index] = state\n",
    "        self.next_states[self.buffer_index] = next_state\n",
    "        self.actions[self.buffer_index] = action\n",
    "        self.rewards[self.buffer_index] = reward\n",
    "        self.terminal[self.buffer_index] = 1 - int(done)\n",
    "        self.buffer_index = (self.buffer_index + 1) % self.buffer_size\n",
    "\n",
    "    def sample_memory(self):\n",
    "        indicies = np.random.randint(0, self.buffer_index, self.batch_size)\n",
    "        return self.states[indicies], self.actions[indicies], self.rewards[indicies], self.next_states[indicies], self.terminal[indicies]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function For Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T03:13:14.236860Z",
     "start_time": "2023-12-20T03:13:14.234892Z"
    }
   },
   "outputs": [],
   "source": [
    "#from keras exactly, site if using!!!\n",
    "def init_deep_q_network(input_shape, lr, num_actions, l1_size, l2_size):\n",
    "    # Network defined by the Deepmind paper\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutions on the frames on the screen\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "\n",
    "    layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer5)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class For Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T03:13:14.242276Z",
     "start_time": "2023-12-20T03:13:14.240095Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, alpha, gamma, actions_amt, epsilon, input_shape, input_shape_attention=(84, 84, 3), epsilon_dec=0.996, epsilon_end=0.01,  batch_size=64, fname='dqn_model.h5', buffer_size=1000, window_x=50, window_y=80):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.actions_amt = actions_amt\n",
    "        self.epsilon = epsilon \n",
    "        self.input_shape = input_shape\n",
    "        self.input_shape_attention = input_shape\n",
    "        self.epsilon_dec = epsilon_dec\n",
    "        self.epsilon_end = epsilon_end\n",
    "        self.fname = fname\n",
    "        self.q_network = init_deep_q_network(input_shape, alpha, actions_amt, 256, 256)\n",
    "        self.q_network_target = init_deep_q_network(input_shape, alpha, actions_amt, 256, 256)\n",
    "        self.attention_q = init_deep_q_network(input_shape_attention, alpha, actions_amt, 256, 256)\n",
    "        self.attention_q_target = init_deep_q_network(input_shape_attention, alpha, actions_amt, 256, 256)\n",
    "        self.memory = Memory(input_shape, actions_amt, buffer_size, batch_size)\n",
    "        self.loss_function = keras.losses.Huber()\n",
    "        self.optimizer = keras.optimizers.legacy.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "        self.model_file = \"rl_agent\"\n",
    "        self.attention_model_file = \"attention_network\"\n",
    "        self.window_x = window_x\n",
    "        self.window_y = window_y\n",
    "\n",
    "\n",
    "    def select_action(self, input, actor=True): \n",
    "        if actor:\n",
    "            network = self.q_network\n",
    "            num_actions = self.actions_amt\n",
    "        else: \n",
    "            network = self.attention_q\n",
    "            num_actions = 5\n",
    "        if np.random.rand() > self.epsilon:\n",
    "            action_values = network.predict(input[None,...], verbose=0)\n",
    "            action = np.argmax(action_values)\n",
    "        else:\n",
    "            action = np.random.choice(num_actions)\n",
    "        \n",
    "        return action \n",
    "    \n",
    "    def store_action(self, state, action, reward, next_state, done, actor=True):\n",
    "        self.memory.save_action(state, action, reward, next_state, done)\n",
    "\n",
    "    def learn(self, actor=True):\n",
    "        if actor:\n",
    "            network = self.q_network\n",
    "            target_network = self.q_network_target\n",
    "        else: \n",
    "            network = self.attention_q\n",
    "            target_network = self.attention_q_target\n",
    "        #print(\"calling learn\")\n",
    "        states, actions, rewards, new_states, dones = self.memory.sample_memory()\n",
    "        states = tf.stack(states)\n",
    "        actions = tf.stack(actions)\n",
    "        new_states = tf.stack(new_states)\n",
    "        dones = tf.stack(dones)\n",
    "        new_states = tf.stack(new_states)\n",
    "        future_rewards = target_network.predict(new_states, verbose=0)\n",
    "        updated_qs = rewards + self.gamma * tf.reduce_max(future_rewards, axis=1)\n",
    "        masks = tf.one_hot(actions, self.actions_amt)\n",
    "        #print(\"before gradient tape section\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            q_values = network(states)\n",
    "            q_actions = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "            loss = self.loss_function(updated_qs, q_actions)\n",
    "        grads = tape.gradient(loss, network.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "        target_network.set_weights(network.get_weights())\n",
    "        \n",
    "        if self.epsilon > self.epsilon_end:\n",
    "            self.epsilon -= self.epsilon_dec\n",
    "\n",
    "    def set_focal_pont(self):\n",
    "        x = 210\n",
    "        y = 160\n",
    "        x_init = (x / 2) - (self.window_x / 2)\n",
    "        y_init = self.window_y / 2\n",
    "        self.focal_point = (x_init, y_init)\n",
    "\n",
    "    def move_focal_point(self, action, stride=5):\n",
    "        x,y = self.focal_point\n",
    "        if action == 0:\n",
    "            x = x - stride\n",
    "        if action == 1:\n",
    "            x = x + stride\n",
    "        if action == 2:\n",
    "            y = y + stride\n",
    "        if action == 3:\n",
    "            y = y - stride\n",
    "        self.focal_point = (x,y)\n",
    "    \n",
    "    def extract_frame(self, input):\n",
    "        focal_point = self.focal_point\n",
    "        x_len, y_len = self.window_x, self.window_y\n",
    "        max_x, max_y,_ = np.shape(input)\n",
    "        x,y = focal_point\n",
    "        x_half = x_len / 2\n",
    "        y_half = y_len /2\n",
    "        x_left = x - x_half\n",
    "        x_right = x + x_half\n",
    "        y_up = y + y_half\n",
    "        y_down = y - y_half\n",
    "        if x_left < 0:\n",
    "            x_left = 0\n",
    "            x_right = x_len\n",
    "        if x_right > max_x - 1:\n",
    "            x_right = max_x - 1\n",
    "            x_left = x_right - x_len\n",
    "        if y_up > max_y - 1:\n",
    "            y_up = max_y - 1\n",
    "            y_down = y_up - y_len\n",
    "        if y_down < 0:\n",
    "            y_down = 0\n",
    "            y_up = y_down + y_len\n",
    "        x_left = int(x_left)\n",
    "        x_right = int(x_right)\n",
    "        y_up = int(y_up)\n",
    "        y_down = int(y_down)\n",
    "        frame = input[x_left:x_right, y_down:y_up]\n",
    "        return frame\n",
    "    \n",
    "    def save_model(self, actor=True):\n",
    "        if actor:\n",
    "            network = self.q_network\n",
    "            file = self.model_file\n",
    "        else: \n",
    "            network = self.attention_q\n",
    "            file = self.attention_model_file\n",
    "        \n",
    "        network.save(file)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.q_network = load_model(self.model_file)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T03:14:01.075312Z",
     "start_time": "2023-12-20T03:13:14.242446Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#env = gym.make('Breakout-v4')\n",
    "env = gym.make('Breakout-v4', render_mode='human')\n",
    "n_games = 150001\n",
    "agent = Agent(gamma=.99, epsilon=.5, alpha=.0005, actions_amt=4, input_shape=(84, 84, 3), batch_size=32, epsilon_end=0.01, buffer_size=1000, epsilon_dec=.01, window_x=84, window_y=84)\n",
    "agent.set_focal_pont()\n",
    "scores = []\n",
    "eps_history = []\n",
    "\n",
    "for i in range(n_games):\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "    observation = observation[0]\n",
    "    observation = agent.extract_frame(observation)\n",
    "    j = 0\n",
    "    while not done: \n",
    "        st = time.time()\n",
    "        action = agent.select_action(observation)\n",
    "        fp_action = agent.select_action(observation, actor=False)\n",
    "        agent.move_focal_point(fp_action)\n",
    "        observation_, reward, done, truncated, info = env.step(action)\n",
    "        observation_ = agent.extract_frame(observation_)\n",
    "        score += reward\n",
    "        agent.store_action(observation, action, reward, observation_, done)\n",
    "        agent.store_action(observation, action, reward, observation_, done, actor=False)\n",
    "        observation = observation_\n",
    "        et= time.time()\n",
    "        j += 1 \n",
    "        if j == 100:\n",
    "            agent.learn()\n",
    "            agent.learn(actor=False)\n",
    "\n",
    "    eps_history.append(agent.epsilon)\n",
    "    scores.append(score)\n",
    "\n",
    "    avg_score = np.mean(scores[max(0, 1 - 100):(i + 1)])\n",
    "    #if i % 10 == 0:\n",
    "    print(\"episode \", i, \"score %.2f\" % score, 'average score %.2f' % avg_score)\n",
    "\n",
    "    #if i % 10 == 0 and i > 0: \n",
    "        #agent.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142 142 142]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20204140bd0>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print((observation[0][0]))\n",
    "plt.imshow(observation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
